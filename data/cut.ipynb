{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THULACï¼ˆæ¸…åå¤§å­¦ä¸­æ–‡è¯æ³•åˆ†æå·¥å…·ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded succeed\n",
      "[['å¥³å£«', 'n'], ['ä¼˜å…ˆ', 'v'], ['ç»…å£«', 'n'], ['é£åº¦', 'n'], ['è¿™äº›', 'r'], ['æ˜¯', 'v'], ['ä»', 'p'], ['è¥¿æ–¹', 's'], ['ä¼ è¿›', 'v'], ['æ¥', 'v'], ['çš„', 'u'], ['ä¸œè¥¿', 'n'], ['ï¼Œ', 'w'], ['ç”·å¥³å¹³ç­‰', 'id'], ['æ‰', 'd'], ['æ˜¯', 'v'], ['å›½ç­–', 'n'], ['ï¼Œ', 'w'], ['è¥¿æ–¹', 's'], ['ç´«è‹¯', 'n'], ['æ»‹å…»', 'v'], ['äº†', 'u'], ['å¥³æ‹³', 'n']]\n"
     ]
    }
   ],
   "source": [
    "import thulac\n",
    "thu = thulac.thulac()\n",
    "text = \"å¥³å£«ä¼˜å…ˆç»…å£«é£åº¦è¿™äº›æ˜¯ä»è¥¿æ–¹ä¼ è¿›æ¥çš„ä¸œè¥¿ï¼Œç”·å¥³å¹³ç­‰æ‰æ˜¯å›½ç­–ï¼Œè¥¿æ–¹ç´«è‹¯æ»‹å…»äº†å¥³æ‹³\"\n",
    "print(thu.cut(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### jiebaåˆ†è¯\n",
    "\n",
    "- åè¯ç±»\n",
    "\n",
    "- n: æ™®é€šåè¯ï¼ˆå¦‚\"é£åº¦\"ï¼‰\n",
    "- nr: äººåï¼ˆå¦‚\"å¥³å£«\"ï¼‰\n",
    "- ns: åœ°åï¼ˆå¦‚\"ä¸œè¥¿\"ï¼‰\n",
    "- nz: å…¶ä»–ä¸“æœ‰åè¯ï¼ˆå¦‚\"ç´«è‹¯\"ï¼‰\n",
    "- l: ä¹ ç”¨è¯­ï¼ˆå¦‚\"ç”·å¥³å¹³ç­‰\"ï¼‰\n",
    "- åŠ¨è¯ç±»\n",
    "\n",
    "- v: æ™®é€šåŠ¨è¯ï¼ˆå¦‚\"æ˜¯\"ã€\"æ»‹å…»\"ï¼‰\n",
    "- vd: åŠ¨å‰¯è¯\n",
    "- vn: ååŠ¨è¯\n",
    "- å½¢å®¹è¯ç±»\n",
    "\n",
    "- a: å½¢å®¹è¯\n",
    "- ad: å‰¯å½¢è¯\n",
    "- an: åå½¢è¯\n",
    "- ä»£è¯ç±»\n",
    "\n",
    "- r: ä»£è¯ï¼ˆå¦‚\"è¿™äº›\"ï¼‰\n",
    "- å‰¯è¯ç±»\n",
    "\n",
    "- d: å‰¯è¯ï¼ˆå¦‚\"æ‰\"ï¼‰\n",
    "- åŠ©è¯ç±»\n",
    "\n",
    "- uj: ç»“æ„åŠ©è¯ï¼ˆå¦‚\"çš„\"ï¼‰\n",
    "- ul: æ—¶æ€åŠ©è¯ï¼ˆå¦‚\"äº†\"ï¼‰\n",
    "- ä»‹è¯ç±»\n",
    "\n",
    "- p: ä»‹è¯\n",
    "- è¿è¯ç±»\n",
    "\n",
    "- c: è¿è¯\n",
    "- å¹è¯ç±»\n",
    "\n",
    "- e: å¹è¯\n",
    "- æ ‡ç‚¹ç¬¦å·ç±»\n",
    "\n",
    "- x: æ ‡ç‚¹ç¬¦å·ï¼ˆå¦‚\"ï¼Œ\"ï¼‰\n",
    "- å…¶ä»–\n",
    "\n",
    "- s: å¤„æ‰€è¯ï¼ˆå¦‚\"è¥¿æ–¹\"ï¼‰\n",
    "- t: æ—¶é—´è¯\n",
    "- m: æ•°è¯\n",
    "- q: é‡è¯\n",
    "- o: æ‹Ÿå£°è¯\n",
    "- h: å‰ç¼€\n",
    "- k: åç¼€\n",
    "- i: æˆè¯­\n",
    "- j: ç®€ç§°ç•¥è¯­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¥³å£«ä¼˜å…ˆ(nr) ç»…å£«é£åº¦(n) è¿™äº›(r) æ˜¯ä»(v) è¥¿æ–¹(s) ä¼ (n) è¿›æ¥(v) çš„(uj) ä¸œè¥¿(ns) ï¼Œ(x) ç”·å¥³å¹³ç­‰(l) æ‰(d) æ˜¯(v) å›½ç­–(n) ï¼Œ(x) è¥¿æ–¹(s) ç´«è‹¯(nz) æ»‹å…»(v) äº†(ul) å¥³æ‹³(n) "
     ]
    }
   ],
   "source": [
    "import jieba.posseg as pseg\n",
    "\n",
    "text = \"å¥³å£«ä¼˜å…ˆç»…å£«é£åº¦è¿™äº›æ˜¯ä»è¥¿æ–¹ä¼ è¿›æ¥çš„ä¸œè¥¿ï¼Œç”·å¥³å¹³ç­‰æ‰æ˜¯å›½ç­–ï¼Œè¥¿æ–¹ç´«è‹¯æ»‹å…»äº†å¥³æ‹³\"\n",
    "words = pseg.cut(text)\n",
    "for word, flag in words:\n",
    "    print(f\"{word}({flag})\", end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HanLPåˆ†è¯å™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CTB5_BIAFFINE_DEP_ZH': 'https://file.hankcs.com/hanlp/dep/biaffine_ctb5_20191229_025833.zip',\n",
       " 'CTB7_BIAFFINE_DEP_ZH': 'https://file.hankcs.com/hanlp/dep/biaffine_ctb7_20200109_022431.zip',\n",
       " 'CTB9_DEP_ELECTRA_SMALL': 'https://file.hankcs.com/hanlp/dep/ctb9_dep_electra_small_20220216_100306.zip',\n",
       " 'PMT1_DEP_ELECTRA_SMALL': 'https://file.hankcs.com/hanlp/dep/pmt_dep_electra_small_20220218_134518.zip',\n",
       " 'CTB9_UDC_ELECTRA_SMALL': 'https://file.hankcs.com/hanlp/dep/udc_dep_electra_small_20220218_095452.zip',\n",
       " 'PTB_BIAFFINE_DEP_EN': 'https://file.hankcs.com/hanlp/dep/ptb_dep_biaffine_20200101_174624.zip'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hanlp\n",
    "hanlp.pretrained.tok.ALL  # æŸ¥çœ‹æ‰€æœ‰å¯ç”¨åˆ†è¯æ¨¡å‹\n",
    "hanlp.pretrained.dep.ALL  # æŸ¥çœ‹æ‰€æœ‰å¯ç”¨ä¾å­˜åˆ†ææ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.ustc.edu.cn/pypi/web/simple\n",
      "Requirement already satisfied: hanlp_restful in c:\\programdata\\anaconda3\\lib\\site-packages (0.0.24)\n",
      "Requirement already satisfied: hanlp-common in c:\\programdata\\anaconda3\\lib\\site-packages (from hanlp_restful) (0.0.23)\n",
      "Requirement already satisfied: phrasetree>=0.0.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from hanlp-common->hanlp_restful) (0.0.9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -okenizers (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -qdm (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -okenizers (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -qdm (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install hanlp_restful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. åˆ†è¯ç»“æœ(tok/fine & tok/coarse) ï¼š\n",
    "- fineæ˜¯ç»†ç²’åº¦åˆ†è¯ï¼Œcoarseæ˜¯ç²—ç²’åº¦åˆ†è¯\n",
    "- åº”ç”¨ï¼šå¯ä½œä¸ºæ–‡æœ¬é¢„å¤„ç†çš„åŸºç¡€æ­¥éª¤\n",
    "\n",
    "2.  è¯æ€§æ ‡æ³¨(pos/ctb/pku/863) ï¼š\n",
    "- ä¸åŒæ ‡å‡†ä¸‹çš„è¯æ€§æ ‡è®°ï¼ˆåè¯/åŠ¨è¯ç­‰ï¼‰\n",
    "- åº”ç”¨ï¼šè¯†åˆ«åè¯çŸ­è¯­ï¼ˆæ½œåœ¨è¯„è®ºå¯¹è±¡ï¼‰å’ŒåŠ¨è¯çŸ­è¯­ï¼ˆæ½œåœ¨è®ºç‚¹ï¼‰\n",
    "\n",
    "3. å‘½åå®ä½“è¯†åˆ«(ner/...) ï¼š\n",
    "- å½“å‰è¾“å‡ºä¸ºç©ºï¼Œå¯èƒ½æœªè¯†åˆ«å‡ºå‘½åå®ä½“\n",
    "- åº”ç”¨ï¼šå¯è¯†åˆ«ç‰¹å®šäººç‰©/åœ°ç‚¹ç­‰æ•æ„Ÿå®ä½“\n",
    "\n",
    "4. è¯­ä¹‰è§’è‰²æ ‡æ³¨(srl) ï¼š\n",
    "- æ ‡æ³¨äº†è°“è¯-è®ºå…ƒç»“æ„ï¼Œå¦‚\"å¥³å£«(ARG0) ä¼˜å…ˆ(PRED)\"\n",
    "- åº”ç”¨ï¼šå¯æå–\"è°å¯¹è°åšäº†ä»€ä¹ˆ\"çš„å®Œæ•´è¯­ä¹‰ç»“æ„\n",
    "\n",
    "5. ä¾å­˜åˆ†æ(dep) ï¼š\n",
    "- æ˜¾ç¤ºè¯è¯­é—´çš„è¯­æ³•å…³ç³»ï¼Œå¦‚nsubj(ä¸»è¯­)ã€dobj(å®¾è¯­)\n",
    "- åº”ç”¨ï¼šè¯†åˆ«å¥å­çš„ä¸»è°“å®¾æ ¸å¿ƒç»“æ„\n",
    "\n",
    "6. è¯­ä¹‰ä¾å­˜åˆ†æ(sdp) ï¼š\n",
    "- æ›´æ·±å±‚çš„è¯­ä¹‰å…³ç³»ï¼Œå¦‚Exp(ä½“éªŒè€…)ã€Pat(å—äº‹)\n",
    "- åº”ç”¨ï¼šç†è§£æ”»å‡»è¡Œä¸ºçš„æ–½å—å…³ç³»\n",
    "\n",
    "7. çŸ­è¯­ç»“æ„æ ‘(con) ï¼š\n",
    "- å®Œæ•´çš„å¥æ³•æ ‘ç»“æ„\n",
    "- åº”ç”¨ï¼šåˆ†æå¤æ‚å¥å­çš„å±‚æ¬¡å…³ç³»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"tok/fine\": [\n",
      "    [\"å¥³å£«\", \"ä¼˜å…ˆ\", \"ç»…å£«\", \"é£åº¦\", \"è¿™äº›\", \"æ˜¯\", \"ä»\", \"è¥¿æ–¹\", \"ä¼ \", \"è¿›æ¥\", \"çš„\", \"ä¸œè¥¿\", \"ï¼Œ\", \"ç”·å¥³\", \"å¹³ç­‰\", \"æ‰\", \"æ˜¯\", \"å›½ç­–\", \"ï¼Œ\", \"è¥¿æ–¹\", \"ç´«è‹¯\", \"æ»‹å…»\", \"äº†\", \"å¥³æ‹³\"]\n",
      "  ],\n",
      "  \"tok/coarse\": [\n",
      "    [\"å¥³å£«ä¼˜å…ˆ\", \"ç»…å£«é£åº¦\", \"è¿™äº›\", \"æ˜¯\", \"ä»\", \"è¥¿æ–¹\", \"ä¼ \", \"è¿›æ¥\", \"çš„\", \"ä¸œè¥¿\", \"ï¼Œ\", \"ç”·å¥³å¹³ç­‰\", \"æ‰æ˜¯\", \"å›½ç­–\", \"ï¼Œ\", \"è¥¿æ–¹\", \"ç´«è‹¯\", \"æ»‹å…»\", \"äº†\", \"å¥³æ‹³\"]\n",
      "  ],\n",
      "  \"pos/ctb\": [\n",
      "    [\"NN\", \"VV\", \"NN\", \"NN\", \"PN\", \"VC\", \"P\", \"NN\", \"VV\", \"VV\", \"DEC\", \"NN\", \"PU\", \"NN\", \"VV\", \"AD\", \"VC\", \"NN\", \"PU\", \"NN\", \"NN\", \"VV\", \"AS\", \"NN\"]\n",
      "  ],\n",
      "  \"pos/pku\": [\n",
      "    [\"n\", \"v\", \"n\", \"n\", \"r\", \"v\", \"p\", \"s\", \"v\", \"v\", \"u\", \"n\", \"w\", \"n\", \"a\", \"d\", \"v\", \"n\", \"w\", \"s\", \"n\", \"v\", \"u\", \"n\"]\n",
      "  ],\n",
      "  \"pos/863\": [\n",
      "    [\"n\", \"v\", \"n\", \"n\", \"r\", \"v\", \"p\", \"ns\", \"v\", \"v\", \"u\", \"n\", \"w\", \"n\", \"a\", \"d\", \"vl\", \"n\", \"w\", \"ns\", \"n\", \"v\", \"u\", \"n\"]\n",
      "  ],\n",
      "  \"ner/msra\": [\n",
      "    []\n",
      "  ],\n",
      "  \"ner/pku\": [\n",
      "    []\n",
      "  ],\n",
      "  \"ner/ontonotes\": [\n",
      "    []\n",
      "  ],\n",
      "  \"srl\": [\n",
      "    [[[\"å¥³å£«\", \"ARG0\", 0, 1], [\"ä¼˜å…ˆ\", \"PRED\", 1, 2]], [[\"è¿™äº›\", \"ARG0\", 4, 5], [\"æ˜¯\", \"PRED\", 5, 6], [\"ä»è¥¿æ–¹ä¼ è¿›æ¥çš„ä¸œè¥¿\", \"ARG1\", 6, 12]], [[\"ä»è¥¿æ–¹\", \"ARG2\", 6, 8], [\"ä¼ \", \"PRED\", 8, 9], [\"ä¸œè¥¿\", \"ARG1\", 11, 12]], [[\"ç”·å¥³\", \"ARG0\", 13, 14], [\"å¹³ç­‰\", \"PRED\", 14, 15]], [[\"ç”·å¥³å¹³ç­‰\", \"ARG0\", 13, 15], [\"æ‰\", \"ARGM-ADV\", 15, 16], [\"æ˜¯\", \"PRED\", 16, 17], [\"å›½ç­–\", \"ARG1\", 17, 18]], [[\"è¥¿æ–¹ç´«è‹¯\", \"ARG0\", 19, 21], [\"æ»‹å…»\", \"PRED\", 21, 22], [\"å¥³æ‹³\", \"ARG1\", 23, 24]]]\n",
      "  ],\n",
      "  \"dep\": [\n",
      "    [[2, \"nsubj\"], [0, \"root\"], [4, \"compound:nn\"], [2, \"dep\"], [12, \"nsubj\"], [12, \"cop\"], [8, \"case\"], [9, \"nmod:prep\"], [12, \"acl\"], [9, \"advmod:rcomp\"], [9, \"mark\"], [2, \"conj\"], [2, \"punct\"], [15, \"nsubj\"], [18, \"nsubj\"], [18, \"advmod\"], [18, \"cop\"], [2, \"conj\"], [2, \"punct\"], [21, \"compound:nn\"], [22, \"nsubj\"], [2, \"conj\"], [22, \"aux:asp\"], [22, \"dobj\"]]\n",
      "  ],\n",
      "  \"sdp\": [\n",
      "    [[[2, \"Exp\"]], [[0, \"Root\"]], [[4, \"Desc\"]], [[2, \"eCoo\"]], [[6, \"Exp\"]], [[9, \"mMod\"]], [[8, \"mPrep\"]], [[9, \"Orig\"]], [[12, \"rCont\"]], [[9, \"mDir\"]], [[9, \"mAux\"]], [[6, \"Clas\"]], [[6, \"mPunc\"]], [[15, \"Exp\"]], [[17, \"dExp\"]], [[17, \"mMod\"]], [[6, \"eSucc\"]], [[17, \"Clas\"]], [[17, \"mPunc\"]], [[21, \"Loc\"]], [[22, \"Exp\"]], [[6, \"eSucc\"], [17, \"eSucc\"]], [[22, \"mTime\"]], [[22, \"Pat\"]]]\n",
      "  ],\n",
      "  \"con\": [\n",
      "    [\"TOP\", [[\"IP\", [[\"IP\", [[\"IP\", [[\"NP\", [[\"NN\", [\"å¥³å£«\"]]]], [\"VP\", [[\"VV\", [\"ä¼˜å…ˆ\"]]]]]], [\"VP\", [[\"NP\", [[\"NN\", [\"ç»…å£«\"]], [\"NN\", [\"é£åº¦\"]]]]]]]], [\"IP\", [[\"NP\", [[\"PN\", [\"è¿™äº›\"]]]], [\"VP\", [[\"VC\", [\"æ˜¯\"]], [\"NP\", [[\"CP\", [[\"CP\", [[\"IP\", [[\"VP\", [[\"PP\", [[\"P\", [\"ä»\"]], [\"NP\", [[\"NN\", [\"è¥¿æ–¹\"]]]]]], [\"VP\", [[\"VRD\", [[\"VV\", [\"ä¼ \"]], [\"VV\", [\"è¿›æ¥\"]]]]]]]]]], [\"DEC\", [\"çš„\"]]]]]], [\"NP\", [[\"NN\", [\"ä¸œè¥¿\"]]]]]]]]]], [\"PU\", [\"ï¼Œ\"]], [\"IP\", [[\"IP\", [[\"NP\", [[\"NN\", [\"ç”·å¥³\"]]]], [\"VP\", [[\"VV\", [\"å¹³ç­‰\"]]]]]], [\"VP\", [[\"ADVP\", [[\"AD\", [\"æ‰\"]]]], [\"VP\", [[\"VC\", [\"æ˜¯\"]], [\"NP\", [[\"NN\", [\"å›½ç­–\"]]]]]]]]]], [\"PU\", [\"ï¼Œ\"]], [\"IP\", [[\"NP\", [[\"NN\", [\"è¥¿æ–¹\"]], [\"NN\", [\"ç´«è‹¯\"]]]], [\"VP\", [[\"VV\", [\"æ»‹å…»\"]], [\"AS\", [\"äº†\"]], [\"NP\", [[\"NN\", [\"å¥³æ‹³\"]]]]]]]]]]]]\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from hanlp_restful import HanLPClient\n",
    "HanLP = HanLPClient('https://www.hanlp.com/api', auth='your_auth')  # authéœ€è¦ç”³è¯·\n",
    "doc = HanLP.parse('å¥³å£«ä¼˜å…ˆç»…å£«é£åº¦è¿™äº›æ˜¯ä»è¥¿æ–¹ä¼ è¿›æ¥çš„ä¸œè¥¿ï¼Œç”·å¥³å¹³ç­‰æ‰æ˜¯å›½ç­–ï¼Œè¥¿æ–¹ç´«è‹¯æ»‹å…»äº†å¥³æ‹³')\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æƒ…æ„Ÿåˆ†æï¼ˆ-1 ~ 1ï¼šæ¶ˆæåˆ°ç§¯æï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3068910837173462"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HanLP.sentiment_analysis('è¥¿æ–¹ç´«è‹¯æ»‹å…»äº†å¥³æ‹³')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç›´æ¥ä½¿ç”¨HanLPçš„å¥å­å…³é”®è¯æå–å’Œæƒ…æ„Ÿåˆ†æå·¥å…·æŸ¥çœ‹æå–å‡†ç¡®ç‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æµ‹è¯•å…³é”®è¯æå–ç»“æœ: ['HanLPçš„å…¨éƒ¨æ€§èƒ½']\n",
      "æµ‹è¯•æƒ…æ„Ÿåˆ†æç»“æœ: -0.6087199449539185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "å¤„ç†è¿›åº¦:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3276/4000 [2:58:03<39:14,  3.25s/æ¡]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å…³é”®è¯æå–å¤±è´¥ï¼Œcontent=ä½ è¯´å¾—å›½æ˜¯æŒ‡å¤§å®‹å—ï¼ŸğŸ˜…å°±æ˜¯è¢«é‡‘å¹²å¾—çš‡ä¸Šéƒ½æ²¡äº†çš„é‚£ä¸ª, é”™è¯¯è¯¦æƒ…=HTTPSConnectionPool(host='www.hanlp.com', port=443): Max retries exceeded with url: /api/keyphrase_extraction (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025995D2F780>: Failed to establish a new connection: [WinError 10060] ç”±äºè¿æ¥æ–¹åœ¨ä¸€æ®µæ—¶é—´åæ²¡æœ‰æ­£ç¡®ç­”å¤æˆ–è¿æ¥çš„ä¸»æœºæ²¡æœ‰ååº”ï¼Œè¿æ¥å°è¯•å¤±è´¥ã€‚'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "å¤„ç†è¿›åº¦: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4000/4000 [3:38:57<00:00,  3.28s/æ¡]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è¯„è®ºå¯¹è±¡æå–å‡†ç¡®ç‡: 25.77%\n",
      "æƒ…æ„Ÿåˆ†ç±»å‡†ç¡®ç‡: 57.99999999999999%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "from tqdm import tqdm \n",
    "from hanlp_restful import HanLPClient\n",
    "\n",
    "# åˆå§‹åŒ–HanLPå®¢æˆ·ç«¯ï¼ˆæ›¿æ¢ä¸ºæ‚¨çš„authä¿¡æ¯ï¼‰\n",
    "HanLP = HanLPClient('https://www.hanlp.com/api', auth='your_auth')\n",
    "\n",
    "def parse_output(output_str):\n",
    "    \"\"\"è§£ææ ‡æ³¨çš„outputå­—ç¬¦ä¸²ï¼Œæå–çœŸå®è¯„è®ºå¯¹è±¡å’Œæƒ…æ„Ÿæ ‡ç­¾\"\"\"\n",
    "    parts = output_str.replace(' [END]', '').split(' [SEP] ')\n",
    "    first_part = parts[0].split(' | ')\n",
    "    true_target = first_part[0].strip()\n",
    "    true_sentiment = first_part[-1].strip()\n",
    "    return true_target, true_sentiment\n",
    "\n",
    "def evaluate(data_path):\n",
    "    # åŠ è½½æ•°æ®\n",
    "    with open(data_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    target_correct = 0\n",
    "    sentiment_correct = 0\n",
    "    total = len(data)\n",
    "    \n",
    "    # æ–°å¢ï¼šåˆå§‹åŒ–è¿›åº¦æ¡ï¼ˆæ€»é•¿åº¦ä¸ºæ•°æ®é‡ï¼‰\n",
    "    pbar = tqdm(total=total, desc=\"å¤„ç†è¿›åº¦\", unit=\"æ¡\")\n",
    "    \n",
    "    for idx, sample in enumerate(data):\n",
    "        content = sample['content']\n",
    "        true_target, true_sentiment = parse_output(sample['output'])\n",
    "        \n",
    "        # 1. è¯„è®ºå¯¹è±¡é¢„æµ‹ï¼ˆå…³é”®è¯æå–ï¼‰\n",
    "        try:\n",
    "            keywords = HanLP.keyphrase_extraction(content, topk=1)\n",
    "            if isinstance(keywords, dict):\n",
    "                keywords = list(keywords.keys())\n",
    "            pred_target = keywords[0] if keywords else 'NULL'\n",
    "        except Exception as e:\n",
    "            pred_target = 'ERROR'\n",
    "            print(f\"å…³é”®è¯æå–å¤±è´¥ï¼Œcontent={content}, é”™è¯¯è¯¦æƒ…={str(e)}\")\n",
    "        \n",
    "        # 2. æƒ…æ„Ÿé¢„æµ‹\n",
    "        try:\n",
    "            sentiment_score = HanLP.sentiment_analysis(content)\n",
    "            pred_sentiment = 'hate' if sentiment_score < 0 else 'non-hate'\n",
    "        except Exception as e:\n",
    "            pred_sentiment = 'ERROR'\n",
    "            print(f\"æƒ…æ„Ÿåˆ†æå¤±è´¥ï¼Œcontent={content}, é”™è¯¯è¯¦æƒ…={str(e)}\")\n",
    "        \n",
    "        # å¯¹æ¯”ç»“æœ\n",
    "        if pred_target == true_target:\n",
    "            target_correct += 1\n",
    "        if pred_sentiment == true_sentiment:\n",
    "            sentiment_correct += 1\n",
    "        \n",
    "        # é¢‘ç‡æ§åˆ¶\n",
    "        if idx < total - 1:\n",
    "            time.sleep(2.5)\n",
    "        \n",
    "        pbar.update(1)\n",
    "    \n",
    "    pbar.close()\n",
    "    \n",
    "    # è®¡ç®—å‡†ç¡®ç‡\n",
    "    target_acc = target_correct / total if total > 0 else 0\n",
    "    sentiment_acc = sentiment_correct / total if total > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        \"target_accuracy\": round(target_acc, 4),\n",
    "        \"sentiment_accuracy\": round(sentiment_acc, 4)\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # æµ‹è¯•HanLPåŸºç¡€åŠŸèƒ½\n",
    "    test_keywords = HanLP.keyphrase_extraction(\n",
    "        'è‡ªç„¶è¯­è¨€å¤„ç†æ˜¯ä¸€é—¨åšå¤§ç²¾æ·±çš„å­¦ç§‘ï¼ŒæŒæ¡ç†è®ºæ‰èƒ½å‘æŒ¥å‡ºHanLPçš„å…¨éƒ¨æ€§èƒ½ã€‚', topk=1\n",
    "    )\n",
    "    if isinstance(test_keywords, dict):\n",
    "        test_keywords = list(test_keywords.keys())\n",
    "    print(\"æµ‹è¯•å…³é”®è¯æå–ç»“æœ:\", test_keywords)\n",
    "    \n",
    "    print(\"æµ‹è¯•æƒ…æ„Ÿåˆ†æç»“æœ:\", HanLP.sentiment_analysis('è¿™æ˜æ˜¾æ˜¯ç»¼è‰ºèŠ‚ç›®å•¥çš„æ¶æå§...'))\n",
    "    \n",
    "    # è¯„ä¼°æ•´ä½“å‡†ç¡®ç‡\n",
    "    result = evaluate('./data.json')\n",
    "    print(f\"è¯„è®ºå¯¹è±¡æå–å‡†ç¡®ç‡: {result['target_accuracy'] * 100}%\")\n",
    "    print(f\"æƒ…æ„Ÿåˆ†ç±»å‡†ç¡®ç‡: {result['sentiment_accuracy'] * 100}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
