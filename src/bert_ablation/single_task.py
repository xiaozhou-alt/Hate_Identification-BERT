'''
single_task ä¸»è¦ä¿®æ”¹ï¼šclass HateSpeechDataset(Dataset) ç±»
ä»…é¢„æµ‹ä»‡æ¨è¨€è®ºçš„ç›®æ ‡ç¾¤ä½“
'''

import torch
from transformers import AutoTokenizer, AutoModel
from transformers import BertModel, BertTokenizer
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import json
from tqdm import tqdm
import re
from difflib import SequenceMatcher
import jieba
from hanlp_restful import HanLPClient
from keyword_config import TARGET_KEYWORDS, HATE_KEYWORDS
HanLP = HanLPClient('https://www.hanlp.com/api', auth='your_auth')  # authéœ€è¦ç”³è¯·

# è‡ªå®šä¹‰æ•°æ®é›†ç±» - ä¿®æ”¹ä¸ºæ”¯æŒå››å…ƒç»„ç”Ÿæˆ
class HateSpeechDataset(Dataset):
    def __init__(self, data_path, tokenizer, max_length=128):
        with open(data_path, 'r', encoding='utf-8') as f:
            self.data = json.load(f)
        self.tokenizer = tokenizer
        self.max_length = max_length
        self.target_groups = [
            'Racism', 'non-hate', 'others', 'Region', 'LGBTQ', 'Sexism',
            'Sexism,Racism', 'Sexism, others', 'Sexism, Racism,others', 'Racism,others',
            'Region,Sexism', 'Region, Racism', 'Region, others', 'LGBTQ, Region',
            'others, Sexism', 'Region, LGBTQ', 'Sexism, Region', 'Racism,Sexism',
            'LGBTQ, others', 'Sexism,Racism,Region', 'LGBTQ,Region, others', 'LGBTQ, Sexism',
            'LGBTQ, Sexism, others', 'Region,Sexism,Racism', 'Racism,Region,Sexism',
            'Sexism, LGBTQ', 'LGBTQ,Sexism,Racism', 'LGBTQ,Racism', 'Region,Racism,others',
            'LGBTQ,Racism,others'
        ]
        
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        item = self.data[idx]
        text = item['content']
        quads = self._parse_quads(item['output'], text)
        
        inputs = self.tokenizer(
            text,
            max_length=self.max_length,
            padding='max_length',
            truncation=True,
            return_tensors='pt'
        )
        
        groups = []
        for quad in quads:
            group = quad['group'] if quad['group'] in self.target_groups else 'others'
            groups.append(self.target_groups.index(group))
        
        if not quads:
            groups = [self.target_groups.index('non-hate')]
        
        return {
            'input_ids': inputs['input_ids'].squeeze(),
            'attention_mask': inputs['attention_mask'].squeeze(),
            'groups': torch.tensor(groups)
        }
    
    def _parse_quads(self, output, text):  # æ·»åŠ textå‚æ•°
        quad_list = []
        for quad in output.split(' [SEP] '):
            parts = quad.split(' | ')
            if len(parts) >= 4:
                target = parts[0]
                argument = parts[1]
                group = parts[2].split(',')[0].strip()
                
                # ç¬¬ä¸€å±‚åˆ¤æ–­ï¼šä¿ç•™åŸæœ‰çš„æ¨¡ç³ŠåŒ¹é…é€»è¾‘
                is_hate = False
                for kw in HATE_KEYWORDS:
                    ratio = SequenceMatcher(None, kw, argument).ratio()
                    if ratio >= 0.3:
                        is_hate = True
                        break
                
                # ç¬¬äºŒå±‚åˆ¤æ–­ï¼šå¦‚æœç¬¬ä¸€å±‚æœªæ£€æµ‹åˆ°ï¼Œåˆ™ä½¿ç”¨å¤šç»´åº¦ç‰¹å¾åˆ¤æ–­
                if not is_hate:
                    features = TextProcessor.extract_hate_features(text, argument)  # ä½¿ç”¨ä¼ å…¥çš„text
                    is_hate = (
                        features['has_insult'] or
                        (features['has_negative_emoji'] and features['is_generalization']) or
                        features['has_dehumanizing']
                    )
                
                quad_list.append({
                    'target': target,
                    'argument': argument,
                    'group': group,
                    'is_hate': 1 if is_hate else 0
                })
        return quad_list
    
    @staticmethod
    def collate_fn(batch):
        # å¤„ç†å˜é•¿åºåˆ—
        input_ids = torch.stack([item['input_ids'] for item in batch])
        attention_mask = torch.stack([item['attention_mask'] for item in batch])
        
        # å¤„ç†å˜é•¿çš„groupså’Œis_hates
        groups = [item['groups'] for item in batch]
        is_hates = [item['is_hates'] for item in batch]
        
        return {
            'input_ids': input_ids,
            'attention_mask': attention_mask,
            'groups': groups,  # ä¿æŒä¸ºåˆ—è¡¨å½¢å¼
            'is_hates': is_hates  # ä¿æŒä¸ºåˆ—è¡¨å½¢å¼
        }

# æ–°å¢æ–‡æœ¬å¤„ç†å·¥å…·ç±»
class TextProcessor:
    @staticmethod
    def extract_targets(text):
        # ä½¿ç”¨HanLPè¿›è¡Œä¾å­˜åˆ†æ
        dep_result = HanLP(text, tasks='dep').get('dep')
        # ä½¿ç”¨HanLPè¿›è¡Œè¯­ä¹‰è§’è‰²æ ‡æ³¨
        srl_result = HanLP(text, tasks='srl').get('srl')
        
        targets = []
        
        # ä»SRLç»“æœä¸­æå–ARG0ï¼ˆæ–½äº‹è€…ï¼‰
        if isinstance(srl_result, list):
            for predicate in srl_result:
                if isinstance(predicate, dict) and 'arguments' in predicate:
                    for role in predicate['arguments']:
                        if isinstance(role, dict) and role.get('type') == 'ARG0':
                            target = role.get('word')
                            # æ£€æŸ¥æ˜¯å¦åœ¨TARGET_KEYWORDSä¸­
                            for group in TARGET_KEYWORDS.values():
                                if target in group:
                                    targets.append(target)
        
        # å¦‚æœæ²¡æœ‰ä»SRLä¸­æ‰¾åˆ°ï¼Œå°è¯•ä»ä¾å­˜åˆ†æä¸­æ‰¾ä¸»è¯­
        if not targets and isinstance(dep_result, list):
            for word in dep_result:
                if isinstance(word, dict) and word.get('deprel') == 'nsubj':  # ä¸»è¯­
                    target = word.get('lemma')
                    for group in TARGET_KEYWORDS.values():
                        if target in group:
                            targets.append(target)
        
        # å¦‚æœè¿˜æ˜¯æ²¡æœ‰æ‰¾åˆ°ï¼Œè®¾ç½®ä¸ºå¥å­çš„ä¸»è¯­ï¼ˆé’ˆå¯¹çŸ­å¥å­ï¼‰
        if not targets and isinstance(dep_result, list):
            # æŸ¥æ‰¾ç¬¬ä¸€ä¸ªä¸»è¯­
            for word in dep_result:
                if isinstance(word, dict) and word.get('deprel') == 'nsubj':
                    targets.append(word.get('lemma'))
                    break
            
            # å¦‚æœæ²¡æœ‰ä¸»è¯­ï¼Œè®¾ç½®ä¸ºnull
            if not targets:
                targets.append('NULL')
        
        return list(set(targets))

    @staticmethod 
    def extract_arguments(text, targets):
        """åŸºäºSRLå’Œä¾å­˜åˆ†ææå–è®ºç‚¹ï¼ˆè¡Œä¸º+å—äº‹ï¼‰"""
        arguments = []
        srl_result = HanLP(text, tasks='srl').get('srl')
        
        for target in targets:
            # æŸ¥æ‰¾åŒ…å«è¯¥targetçš„è°“è¯-è®ºå…ƒç»“æ„
            if isinstance(srl_result, list):
                for predicate in srl_result:
                    if isinstance(predicate, dict) and 'arguments' in predicate:
                        args = {}
                        for arg in predicate['arguments']:
                            if isinstance(arg, dict) and 'type' in arg and 'word' in arg:
                                args[arg['type']] = arg['word']
                        if 'ARG0' in args and args['ARG0'] == target:
                            # ç»„åˆè¡Œä¸ºå’Œå—äº‹
                            argument = predicate.get('word', '')  # è¡Œä¸º
                            if 'ARG1' in args:  # å—äº‹
                                argument += ' ' + args['ARG1']
                            arguments.append(argument)
        
        # å¦‚æœæ²¡æœ‰ä»SRLä¸­æ‰¾åˆ°ï¼Œå°è¯•ä»ä¾å­˜åˆ†æä¸­æå–
        if not arguments:
            dep_result = HanLP(text, tasks='dep').get('dep')
            if isinstance(dep_result, list):
                for target in targets:
                    for word in dep_result:
                        if isinstance(word, dict) and word.get('lemma') == target and word.get('deprel') == 'nsubj':
                            # æ‰¾è¯¥ä¸»è¯­çš„è°“è¯­å’Œå®¾è¯­
                            head = word.get('head', 0)
                            predicate = dep_result[head-1].get('lemma', '') if head > 0 else ''
                            obj = ''
                            for w in dep_result:
                                if isinstance(w, dict) and w.get('head') == head and w.get('deprel') == 'dobj':
                                    obj = w.get('lemma', '')
                            argument = f"{predicate} {obj}".strip()
                            if argument:
                                arguments.append(argument)
        
        return arguments if arguments else [text]

    @staticmethod
    def extract_hate_features(text, argument):
        features = {
            'has_hate_keyword': any(kw in argument for kw in HATE_KEYWORDS),
            'has_insult': len(re.findall(r'[å‚»ç¬¨è ¢è´±ä¸‘æ‡’è„å]', argument)) > 0,
            'has_negative_emoji': len(re.findall(r'[ğŸ¶ğŸ¤®ğŸ¤¢ğŸ¤¬ğŸ‘ğŸ˜“ğŸ”ª]', argument)) > 0,
            'is_generalization': any(word in argument for word in ['éƒ½', 'å…¨', 'æ€»æ˜¯']),
            'has_dehumanizing': any(term in argument for term in ['ä¸œè¥¿', 'è´§', 'ç©æ„å„¿'])
        }
        return features

def predict_quads(text, model, tokenizer, device='cuda'):
    processor = TextProcessor()
    targets = processor.extract_targets(text)
    arguments = processor.extract_arguments(text, targets)
    
    quads = []
    for target, arg in zip(targets, arguments):
        # åˆ¤æ–­group
        group = 'others'
        for g, kws in TARGET_KEYWORDS.items():
            if target in kws:
                group = g
                break
        
        # æƒ…æ„Ÿåˆ†æåˆ¤æ–­hate/non-hate
        sentiment = HanLP.sentiment_analysis(arg)
        is_hate = 'hate' if sentiment < 0 else 'non-hate'
        
        quads.append(f"{target} | {arg} | {group} | {is_hate}")
    
    return " [SEP] ".join(quads) + " [END]" if quads else " |  | non-hate | non-hate [END]"

# ä¿®æ”¹è®­ç»ƒå‡½æ•°ä»¥æ”¯æŒå››å…ƒç»„é¢„æµ‹
def finetune_chatglm():
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # ä¿®æ”¹æ¨¡å‹åŠ è½½æ–¹å¼ä¸ºINT4é‡åŒ–ç‰ˆæœ¬
    model_name = "/kaggle/input/bert/transformers/default/1/bert-base-chinese"
    tokenizer = BertTokenizer.from_pretrained(model_name)
    model = BertModel.from_pretrained(model_name).to(device)
    
    # æ·»åŠ æ•°æ®é›†åŠ è½½
    train_dataset = HateSpeechDataset(
        '/kaggle/input/hate-identification/train.json',  # è¯·ç¡®è®¤å®é™…è·¯å¾„
        tokenizer,
        max_length=128
    )
    train_loader = DataLoader(
        train_dataset,
        batch_size=32,
        shuffle=True,
        collate_fn=HateSpeechDataset.collate_fn  # ä½¿ç”¨è‡ªå®šä¹‰collateå‡½æ•°
    )
    
    # æ·»åŠ å››å…ƒç»„é¢„æµ‹å¤´
    model.group_classifier = torch.nn.Linear(model.config.hidden_size, 29).cuda()  # ä¿®æ”¹ä¸º29ä¸ªç±»åˆ«
    
    # ä¿®æ”¹ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡ï¼ŒBERTé€šå¸¸ä½¿ç”¨è¾ƒå°çš„å­¦ä¹ ç‡
    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)
    group_criterion = nn.CrossEntropyLoss()
    hate_criterion = nn.BCEWithLogitsLoss()
    
    # åœ¨è®­ç»ƒå¾ªç¯ä¸­æ·»åŠ æ¢¯åº¦ç´¯ç§¯
    gradient_accumulation_steps = 4
    
    # è®­ç»ƒå¾ªç¯
    epoch_num = 15
    
    torch.cuda.empty_cache()
    model.train()
    # ä¿®æ”¹è®­ç»ƒå¾ªç¯éƒ¨åˆ†
    for epoch in range(epoch_num):
        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epoch_num}')
        
        for batch_idx, batch in enumerate(progress_bar):
            optimizer.zero_grad()
            
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            
            # å‰å‘ä¼ æ’­
            outputs = model(input_ids, attention_mask=attention_mask)
            cls_embedding = outputs.last_hidden_state[:, 0, :]
            
            # è®¡ç®—æ‰€æœ‰æ ·æœ¬çš„æŸå¤±
            total_loss = 0
            batch_group_loss = 0
            
            # å¤„ç†æ¯ä¸ªæ ·æœ¬çš„å››å…ƒç»„
            for i in range(len(batch['groups'])):
                # è·å–å½“å‰æ ·æœ¬çš„é¢„æµ‹å’Œæ ‡ç­¾
                group_logits = model.group_classifier(cls_embedding[i].unsqueeze(0))
                
                # ç¡®ä¿æ ‡ç­¾å½¢çŠ¶åŒ¹é…
                group_labels = batch['groups'][i].to(device).long()
                
                # è®¡ç®—æŸå¤±
                group_loss = group_criterion(
                    group_logits.repeat(group_labels.size(0), 1),
                    group_labels
                )
                
                total_loss += group_loss / gradient_accumulation_steps
            
            total_loss.backward()
            
            if (batch_idx + 1) % gradient_accumulation_steps == 0:
                optimizer.step()
                optimizer.zero_grad()
            
            progress_bar.set_postfix({'loss': total_loss.item()})
    
    # ä¿å­˜å®Œæ•´æ¨¡å‹
    print("æ¨¡å‹å·²ä¿å­˜ï¼")
    torch.save(model.state_dict(), '/kaggle/working/bert_model.pth')

if __name__ == "__main__":
    finetune_chatglm()